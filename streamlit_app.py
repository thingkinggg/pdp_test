import streamlit as st
import pandas as pd
import json
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain_openai import AzureChatOpenAI

st.set_page_config(page_title="PDP USP Matcher", layout="wide")

# === íŒŒì¼ ì—…ë¡œë“œ ===
st.sidebar.header("ë°ì´í„° ì—…ë¡œë“œ")
brastemp_file = st.sidebar.file_uploader("Brastemp Parquet íŒŒì¼", type=["parquet"])
electrolux_file = st.sidebar.file_uploader("Electrolux Parquet íŒŒì¼", type=["parquet"])

@st.cache_data
def load_data(file):
    return pd.read_parquet(file)

if brastemp_file and electrolux_file:
    brastemp_df = load_data(brastemp_file)
    electrolux_df = load_data(electrolux_file)

    st.success("âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ")

    # ì œí’ˆ ì„ íƒ
    selected_brastemp = st.selectbox("ğŸ” Brastemp ì œí’ˆ ì„ íƒ", brastemp_df['product_name'].unique())
    br_row = brastemp_df[brastemp_df['product_name'] == selected_brastemp].iloc[0]

    # TF-IDF ìœ ì‚¬ë„ ê¸°ë°˜ Electrolux ë§¤ì¹­
    def find_best_match(base_text, candidates):
        vectorizer = TfidfVectorizer().fit([base_text] + candidates)
        tfidf = vectorizer.transform([base_text] + candidates)
        scores = cosine_similarity(tfidf[0:1], tfidf[1:]).flatten()
        best_idx = scores.argmax()
        return best_idx, scores[best_idx]

    el_idx, sim_score = find_best_match(br_row['usp_details'], electrolux_df['usp_details'].tolist())
    el_row = electrolux_df.iloc[el_idx]

    # ì œí’ˆ ë¹„êµ UI
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("ğŸ¥‡ Brastemp ì œí’ˆ")
        st.markdown(f"**ì œí’ˆëª…:** {br_row['product_name']}")
        st.markdown(f"**ê°€ê²©:** R${br_row['price']:,}")
        st.markdown("**USP ëª©ë¡:**")
        st.write(br_row['usp_details'])

    with col2:
        st.subheader("ğŸ¤– ê°€ì¥ ìœ ì‚¬í•œ Electrolux ì œí’ˆ")
        st.markdown(f"**ì œí’ˆëª…:** {el_row['product_name']}")
        st.markdown(f"**ê°€ê²©:** R${el_row['price']:,}")
        st.markdown(f"**ìœ ì‚¬ë„ ì ìˆ˜:** {sim_score:.2f}")
        st.markdown("**USP ëª©ë¡:**")
        st.write(el_row['usp_details'])

    st.divider()

    # === ê¸°ëŠ¥ 1: SPEC ë¹„êµ ===
    with st.expander("ğŸ” ì œí’ˆ SPEC ë¹„êµ"):
        br_specs = json.loads(br_row['specs'])
        el_specs = json.loads(el_row['specs'])
        spec_keys = sorted(set(br_specs.keys()).union(el_specs.keys()))
        spec_data = {
            "í•­ëª©": spec_keys,
            "Brastemp": [br_specs.get(k, "") for k in spec_keys],
            "Electrolux": [el_specs.get(k, "") for k in spec_keys]
        }
        st.dataframe(pd.DataFrame(spec_data))

    # === ê¸°ëŠ¥ 2: USP ìš”ì•½ (LangChain + Azure OpenAI)
    with st.expander("ğŸ“Œ USP ë¶„ì„ ê²°ê³¼ ìš”ì•½ (Azure OpenAI ê¸°ë°˜)"):
        required_keys = ["AZURE_API_KEY", "AZURE_ENDPOINT", "DEPLOYMENT_NAME"]

        # LangChain LLM ì„¤ì •
        llm = AzureChatOpenAI(
            openai_api_key="e80449f0e6f345bf8311a3f48004f3ba",
            azure_endpoint="https://dhnp.openai.azure.com/",
            deployment_name="gpt-4o",
            api_version="2024-02-01",
            temperature=0
            )

        template = """
            ë‹¤ìŒì€ Brastemp ë° Electroluxì˜ ëƒ‰ì¥ê³  ì œí’ˆì˜ USP ëª©ë¡ì…ë‹ˆë‹¤.
            Brastemp:
            {br_usp}

            Electrolux:
            {el_usp}

            ë‘ ì œí’ˆì˜ íŠ¹ì§•ì„ ë¹„êµí•˜ê³ , ì£¼ìš” ì°¨ì´ì ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”. 
            """
        prompt = PromptTemplate(
                input_variables=["br_usp", "el_usp"],
                template=template.strip()
            )

        chain = LLMChain(llm=llm, prompt=prompt)
        summary = chain.run(br_usp=br_row['usp_details'], el_usp=el_row['usp_details'])

        st.markdown("### âœ… ìš”ì•½ ê²°ê³¼")
        st.write(summary)

else:
    st.info("ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ Brastemp, Electrolux ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
