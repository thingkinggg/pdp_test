import streamlit as st
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import json
import openai

st.set_page_config(page_title="PDP USP Matcher", layout="wide")

# === íŒŒì¼ ì—…ë¡œë“œ ===
st.sidebar.header("ë°ì´í„° ì—…ë¡œë“œ")
brastemp_file = st.sidebar.file_uploader("Brastemp Parquet íŒŒì¼", type=["parquet"])
electrolux_file = st.sidebar.file_uploader("Electrolux Parquet íŒŒì¼", type=["parquet"])

@st.cache_data
def load_data(file):
    return pd.read_parquet(file)

if brastemp_file and electrolux_file:
    brastemp_df = load_data(brastemp_file)
    electrolux_df = load_data(electrolux_file)

    st.success("âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ")

    # ì œí’ˆ ì„ íƒ
    selected_brastemp = st.selectbox("ğŸ” Brastemp ì œí’ˆ ì„ íƒ", brastemp_df['product_name'].unique())
    br_row = brastemp_df[brastemp_df['product_name'] == selected_brastemp].iloc[0]

    # TF-IDF ìœ ì‚¬ë„ ê¸°ë°˜ Electrolux ë§¤ì¹­
    def find_best_match(base_text, candidates):
        vectorizer = TfidfVectorizer().fit([base_text] + candidates)
        tfidf = vectorizer.transform([base_text] + candidates)
        scores = cosine_similarity(tfidf[0:1], tfidf[1:]).flatten()
        best_idx = scores.argmax()
        return best_idx, scores[best_idx]

    el_idx, sim_score = find_best_match(br_row['usp_details'], electrolux_df['usp_details'].tolist())
    el_row = electrolux_df.iloc[el_idx]

    col1, col2 = st.columns(2)
    with col1:
        st.subheader("ğŸ¥‡ Brastemp ì œí’ˆ")
        st.markdown(f"**ì œí’ˆëª…:** {br_row['product_name']}")
        st.markdown(f"**ê°€ê²©:** R${br_row['price']:,}")
        st.markdown("**USP ëª©ë¡:**")
        st.write(br_row['usp_details'])

    with col2:
        st.subheader("ğŸ¤– ê°€ì¥ ìœ ì‚¬í•œ Electrolux ì œí’ˆ")
        st.markdown(f"**ì œí’ˆëª…:** {el_row['product_name']}")
        st.markdown(f"**ê°€ê²©:** R${el_row['price']:,}")
        st.markdown(f"**ìœ ì‚¬ë„ ì ìˆ˜:** {sim_score:.2f}")
        st.markdown("**USP ëª©ë¡:**")
        st.write(el_row['usp_details'])

    st.divider()

    # === ì¶”ê°€ ê¸°ëŠ¥ 1: SPEC ë¹„êµ ===
    with st.expander("ğŸ” ì œí’ˆ SPEC ë¹„êµ"):
        br_specs = json.loads(br_row['specs'])
        el_specs = json.loads(el_row['specs'])
        spec_keys = sorted(set(br_specs.keys()).union(el_specs.keys()))

        spec_data = {
            "í•­ëª©": spec_keys,
            "Brastemp": [br_specs.get(k, "") for k in spec_keys],
            "Electrolux": [el_specs.get(k, "") for k in spec_keys]
        }
        st.dataframe(pd.DataFrame(spec_data))

    # === ì¶”ê°€ ê¸°ëŠ¥ 2: USP ë¶„ì„ ìš”ì•½ ===
    with st.expander("ğŸ“Œ USP ë¶„ì„ ê²°ê³¼ ìš”ì•½ (Azure OpenAI ê¸°ë°˜)"):
        required_keys = ["AZURE_OPENAI_KEY", "AZURE_ENDPOINT", "DEPLOYMENT_NAME"]
        if not all(k in st.secrets for k in required_keys):
            st.warning("Azure OpenAI ì„¤ì •ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤. `.streamlit/secrets.toml`ì— AZURE_API_KEY, AZURE_ENDPOINT, DEPLOYMENT_NAMEë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
        else:
            openai.api_type = "azure"
            openai.api_key = st.secrets["AZURE_OPENAI_KEY"]
            openai.api_base = st.secrets["AZURE_ENDPOINT"]
            openai.api_version = "2023-05-15"
            deployment_name = st.secrets["DEPLOYMENT_NAME"]

            prompt = f"""
            ë‹¤ìŒì€ Brastemp ë° Electroluxì˜ ëƒ‰ì¥ê³  ì œí’ˆì˜ USP ëª©ë¡ì…ë‹ˆë‹¤.
            Brastemp:
            {br_row['usp_details']}

            Electrolux:
            {el_row['usp_details']}

            ì´ ë‘ ì œí’ˆì˜ íŠ¹ì§•ì„ ë¹„êµí•´ì£¼ì‹œê³ , ì–´ë–¤ ì°¨ë³„ì ì´ ìˆëŠ”ì§€ ìš”ì•½í•´ ì£¼ì„¸ìš”. 
            """

            response = openai.ChatCompletion.create(
                engine=deployment_name,
                messages=[{"role": "user", "content": prompt}]
            )

            st.markdown(response["choices"][0]["message"]["content"])
else:
    st.info("ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ Brastemp, Electrolux ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
